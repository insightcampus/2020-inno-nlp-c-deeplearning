{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05 Prac. CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2020-nlp-c/nlp-deeplearning/blob/master/05_Prac_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9THKomKIxvC",
        "colab_type": "text"
      },
      "source": [
        "# 5장. CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVu3zcxEOq6a",
        "colab_type": "text"
      },
      "source": [
        "#1 CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG9HYp3-I5sg",
        "colab_type": "text"
      },
      "source": [
        "https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/tutorials/images/cnn.ipynb?hl=ko#scrollTo=jKgyC5K_4O0d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jRFxccghyMVo"
      },
      "source": [
        "###1) MNIST 데이터셋 다운로드하고 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JWoEqyMuXFF4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "92f2d08d-7b05-49ab-8f15-cdfa8882d162"
      },
      "source": [
        "#!pip install tensorflow-gpu==2.0.0-rc1\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)) #데이터 건수, 이미지 높이, 이미지 너비, 컬러 채널\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)) #데이터 건수, 이미지 높이, 이미지 너비, 컬러 채널\n",
        "\n",
        "# 픽셀 값을 0~1 사이로 정규화합니다.\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Oewp-wYg31t9"
      },
      "source": [
        "### 2) CNN 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L9YmGQBQPrdn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "725b1380-c7c0-4621-b13b-251a28fc882d"
      },
      "source": [
        "model = models.Sequential()\n",
        "# 특징 추출 (Feature Extraction)\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) # 32 * 3 * 3 + 32 = 320\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu')) # 32 * 64 * 3 * 3 + 64 = 18496\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu')) # 64 * 64 * 3 * 3 + 64 = 36928\n",
        "\n",
        "# 분류 (Classification)\n",
        "model.add(layers.Flatten()) # 576개 벡터로 Flatten\n",
        "model.add(layers.Dense(64, activation='relu')) # 576 * 64 + 64 = 36928\n",
        "model.add(layers.Dense(10, activation='softmax')) # 64 * 10 + 10 = 650\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P3odqfHP4M67"
      },
      "source": [
        "### 3) 모델 컴파일과 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MdDzI75PUXrG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b42b3909-6aa4-41fa-d6fb-62618934c88f"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1432 - accuracy: 0.9561\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0469 - accuracy: 0.9858\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0327 - accuracy: 0.9898\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0256 - accuracy: 0.9919\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0203 - accuracy: 0.9934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f62c3cffb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jKgyC5K_4O0d"
      },
      "source": [
        "###4) 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gtyDF0MKUcM7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "13d7cb8b-9df9-4d64-9b4e-76d0fa6d5c9c"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.0313 - accuracy: 0.9909\n",
            "0.9908999800682068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUJN6pqEOaIy",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bvGKMdSOVyC",
        "colab_type": "text"
      },
      "source": [
        "# 2 CNN for Sentence Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCJC8o7KfTNN",
        "colab_type": "text"
      },
      "source": [
        "##1) 네이버 영화 리뷰 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNriA4DKNVgQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "ed2051cf-f690-4d32-f76f-a2a40d6eaa15"
      },
      "source": [
        "# 네이버 영화 리뷰 다운로드\n",
        "!wget https://github.com/e9t/nsmc/raw/master/ratings.txt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv(\"./ratings.txt\",sep='\\t').dropna()\n",
        "df.head(5)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-23 09:54:08--  https://github.com/e9t/nsmc/raw/master/ratings.txt\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt [following]\n",
            "--2020-08-23 09:54:08--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19515078 (19M) [text/plain]\n",
            "Saving to: ‘ratings.txt.3’\n",
            "\n",
            "\rratings.txt.3         0%[                    ]       0  --.-KB/s               \rratings.txt.3        32%[=====>              ]   6.01M  30.0MB/s               \rratings.txt.3       100%[===================>]  18.61M  63.2MB/s    in 0.3s    \n",
            "\n",
            "2020-08-23 09:54:09 (63.2 MB/s) - ‘ratings.txt.3’ saved [19515078/19515078]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8112052</td>\n",
              "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8132799</td>\n",
              "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4655635</td>\n",
              "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9251303</td>\n",
              "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10067386</td>\n",
              "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
              "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
              "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
              "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
              "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rfddH3RfXLe",
        "colab_type": "text"
      },
      "source": [
        "##2) 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPgNyyoXkB6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from tensorflow.keras import preprocessing\n",
        "\n",
        "def preprocess(x, y, padding_size = 128, oov_token=\"<UNK>\", vocab_file = \"vocab.json\") :  \n",
        "  preprocessor = preprocessing.text.Tokenizer(oov_token=oov_token) #토큰화\n",
        "  preprocessor.fit_on_texts(x)\n",
        "  x = preprocessor.texts_to_sequences(x) #시퀀스로 변환\n",
        "  vocab = preprocessor.word_index #단어:인덱스 dictionary\n",
        "  json.dump(vocab, open(vocab_file, 'w'), ensure_ascii=False)\n",
        "  x = preprocessing.sequence.pad_sequences(x, maxlen=padding_size, padding='post', truncating='post')\n",
        "\n",
        "  return x, y, vocab\n",
        "\n",
        "x_train, y_train, vocab = preprocess(df[\"document\"].tolist(), df[\"label\"].tolist())\n",
        "x_train = x_train[:10000]\n",
        "y_train = y_train[:10000]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzkqF56qfavV",
        "colab_type": "text"
      },
      "source": [
        "##3) 모델 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrSyfNITYP6U",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://miro.medium.com/max/770/0*wigQtmJiv0bddwPI.\" width=\"500\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx6gRwN6Oczp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "48b10c7f-a8af-4f57-e620-979e37d62c14"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "def CNNforText( num_classes,  #클래스 갯수\n",
        "          vocab_size,\n",
        "          embed_size = 512, #단어 임베딩 사이즈                 \n",
        "          filter_sizes = [3,4,5],\n",
        "          regularizers_lambda = 0.01, #L2 regulation parameter\n",
        "          dropout =  0.5,\n",
        "          feature_size = 128, #문장 시퀀스 길이\n",
        "          num_filters = 128 #필터 개수 (필터사이즈와 같음). mhlee 하나로 통일하자\n",
        ") :\n",
        "          \n",
        "\n",
        "  inputs = keras.Input(shape=(feature_size,), name='input_data')\n",
        "  embed_initer = keras.initializers.RandomUniform(minval=-1, maxval=1)\n",
        "  #sequence 임베딩\n",
        "  embed = keras.layers.Embedding(vocab_size, embed_size,\n",
        "                                  embeddings_initializer=embed_initer,\n",
        "                                  input_length=feature_size,\n",
        "                                  name='embedding')(inputs)\n",
        "                                  \n",
        "  embed = keras.layers.Reshape((feature_size, embed_size, 1), name='add_channel')(embed)\n",
        "\n",
        "  pool_outputs = []\n",
        "\n",
        "  #filter 별로 모델 구성\n",
        "  for filter_size in filter_sizes :\n",
        "    #convolution\n",
        "    filter_shape = (filter_size, embed_size)\n",
        "    conv = keras.layers.Conv2D(num_filters, filter_shape, strides=(1, 1), padding='valid',\n",
        "                                data_format='channels_last', activation='relu',\n",
        "                                kernel_initializer='glorot_normal',\n",
        "                                bias_initializer=keras.initializers.constant(0.1),\n",
        "                                name='convolution_{:d}'.format(filter_size))(embed)\n",
        "    #max pooling\n",
        "    max_pool_shape = (feature_size - filter_size + 1, 1)\n",
        "    pool = keras.layers.MaxPool2D(pool_size=max_pool_shape,\n",
        "                                  strides=(1, 1), padding='valid',\n",
        "                                  data_format='channels_last',\n",
        "                                  name='max_pooling_{:d}'.format(filter_size))(conv)\n",
        "    pool_outputs.append(pool)\n",
        "\n",
        "  pool_outputs = keras.layers.concatenate(pool_outputs, axis=-1, name='concatenate')\n",
        "  pool_outputs = keras.layers.Flatten(data_format='channels_last', name='flatten')(pool_outputs)\n",
        "  pool_outputs = keras.layers.Dropout(dropout, name='dropout')(pool_outputs)\n",
        "\n",
        "  outputs = keras.layers.Dense(num_classes, activation='softmax',\n",
        "                                kernel_initializer='glorot_normal',\n",
        "                                bias_initializer=keras.initializers.constant(0.1),\n",
        "                                kernel_regularizer=keras.regularizers.l2(regularizers_lambda),\n",
        "                                bias_regularizer=keras.regularizers.l2(regularizers_lambda),\n",
        "                                name='dense')(pool_outputs)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  model.summary()\n",
        "  return model, num_classes\n",
        "\n",
        "model, num_classes = CNNforText(len(np.unique(y_train)), len(vocab))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_data (InputLayer)         [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 128, 512)     188943872   input_data[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_channel (Reshape)           (None, 128, 512, 1)  0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "convolution_3 (Conv2D)          (None, 126, 1, 128)  196736      add_channel[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "convolution_4 (Conv2D)          (None, 125, 1, 128)  262272      add_channel[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "convolution_5 (Conv2D)          (None, 124, 1, 128)  327808      add_channel[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling_3 (MaxPooling2D)    (None, 1, 1, 128)    0           convolution_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling_4 (MaxPooling2D)    (None, 1, 1, 128)    0           convolution_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling_5 (MaxPooling2D)    (None, 1, 1, 128)    0           convolution_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1, 1, 384)    0           max_pooling_3[0][0]              \n",
            "                                                                 max_pooling_4[0][0]              \n",
            "                                                                 max_pooling_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 384)          0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 384)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            385         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 189,731,073\n",
            "Trainable params: 189,731,073\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLYN-56TfrPS",
        "colab_type": "text"
      },
      "source": [
        "##4) 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdwIPx2rdEmA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "78b3c9a6-ce7d-457a-d613-188228ec1da5"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "def train(model, x_train, y_train, num_classes\n",
        "          , batch_size = 64, epochs = 1, fraction_validation = 0.05, results_dir = \"./result/\", save_path = \"model\") :\n",
        "  timestamp = time.strftime(\"%Y-%m-%d-%H-%M\", time.localtime(time.time()))\n",
        "  path = os.path.join(results_dir, timestamp)\n",
        "  if not os.path.exists(path) :    \n",
        "    path_log = os.path.join(path, 'log/')\n",
        "    os.makedirs(path_log)\n",
        "\n",
        "  model.compile(tf.optimizers.Adam(), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  #모델 구조 이미지 파일로 저장\n",
        "  keras.utils.plot_model(model, show_shapes=True, to_file=os.path.join(path, \"model.jpg\"))\n",
        "  y_train = tf.one_hot(y_train, num_classes)\n",
        "  tb_callback = keras.callbacks.TensorBoard(path_log,\n",
        "                                            histogram_freq=0.1, write_graph=True,\n",
        "                                            write_images=True,\n",
        "                                            embeddings_freq=0.5, update_freq='batch')\n",
        "\n",
        "  history = model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=epochs,\n",
        "                                callbacks=[tb_callback], validation_split=fraction_validation, shuffle=True)\n",
        "  \n",
        "  #모델 저장\n",
        "  keras.models.save_model(model, save_path)\n",
        "  print(history.history)\n",
        "\n",
        "  return model, path_log\n",
        "\n",
        "model, path_log = train(model, x_train, y_train, num_classes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  1/149 [..............................] - ETA: 0s - loss: 0.0215 - accuracy: 0.0000e+00WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "149/149 [==============================] - 282s 2s/step - loss: 0.0740 - accuracy: 0.0000e+00 - val_loss: 0.2023 - val_accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: model/assets\n",
            "{'loss': [0.07399430871009827], 'accuracy': [0.0], 'val_loss': [0.20230326056480408], 'val_accuracy': [0.0]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxKDmHsEwLmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {path_log}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1brKOSoNpqE8",
        "colab_type": "text"
      },
      "source": [
        "##5) 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuKxvAvMps3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "def test(model, x_test, y_test):\n",
        "    y_pred_one_hot = model.predict(x=x_test, batch_size=1, verbose=1)\n",
        "    y_pred = tf.math.argmax(y_pred_one_hot, axis=1)\n",
        "\n",
        "    print('\\nTest accuracy: {}\\n'.format(accuracy_score(y_test, y_pred)))\n",
        "    print('Classification report:')\n",
        "    target_names = ['class {:d}'.format(i) for i in np.arange(args.num_classes)]\n",
        "    print(classification_report(y_test, y_pred, target_names=target_names, digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}